\documentclass[]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
%\usepackage[left=1cm, right=1cm, bottom=1cm, top=1cm]{geometry}
\usepackage{fixltx2e}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{stmaryrd}
\usepackage{bbm}
\usepackage[dvipsnames, x11names, rgb]{xcolor}
\usepackage{tikz}
\usetikzlibrary{snakes,arrows,shapes}
\usepackage{algorithm2e}
\usepackage{multicol}
\usepackage{tabularx}
\usepackage{listings}
\usepackage{ebproof}
\newcommand{\sem}[1]{\llbracket #1 \rrbracket}

\MakeRobust{\overrightarrow}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\newcommand{\vc}[1]{\overrightarrow{#1}}
\newcommand{\A}{\mathscr{A}}
\newcommand{\F}{\mathscr{F}}
\newcommand{\B}{\mathscr{B}}
\newcommand{\C}{\mathscr{C}}
\newcommand{\G}{\mathscr{G}}
\renewcommand{\L}{\mathscr{L}}
\newcommand{\V}{\mathscr{V}}
\newcommand{\T}{\mathscr{T}}
\newcommand{\Q}{\mathscr{Q}}
\renewcommand{\H}{\mathscr{H}}
\renewcommand{\P}{\mathscr{P}}
\newcommand{\Er}{\mathscr{E}}
\newcommand{\parts}{\mathscr{P}}
\newcommand{\ntoi}{{n\rightarrow\infty}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\1}{\mathbbm{1}}
\newcommand{\0}{\mathbbm{0}}
\renewcommand{\S}{\mathbb{S}}
\renewcommand{\V}{\mathbb{V}}
\renewcommand{\phi}{\varphi}

\newtheorem{theo}{Theorem}
\newtheorem{lem}{Lemma}
\newtheorem{prop}{Proposition}
\newtheorem{defi}{Definition}
\newtheorem{fact}{Fact}
\newtheorem{ex}{Example}
\newenvironment{prf}{\paragraph{Proof}}{\hfill$\square$}

\newcommand{\Prop}{\text{Prop}}
\newcommand{\Sym}{\text{Sym}}
\newcommand{\Var}{\text{Var}}
\newcommand{\Seq}{\text{Seq}}
\newcommand{\Map}{\text{Map}}
\newcommand{\Set}{\text{Set}}
\newcommand{\dom}{\text{dom}}
\newcommand{\sset}{{\Set_\sigma}}
\newcommand{\mfill}{\hspace*{\fill}}
\newcommand{\proof}[1]{{\scantokens{\begin{prooftree}#1\end{prooftree}}}}
\renewcommand{\subset}{\subseteq}

\setlength{\jot}{1.5ex}

\begin{document}
\title{Optimizing Fluid Construction Grammar}
\author{Luc Chabassier}
\maketitle

\tableofcontents

\section{Introduction}

Fluid Construction Grammar is an implementation of a construction grammar,
based on unification, in Lisp.
% TODO details

We aim to optimize it by giving a criterion to find constructions which
\emph{commutes}, meaning that applying them will not reduce the possibilities.
This should allow to reduce the search path by allowing to apply them
exhaustively first when looking for a derivation. This idea is inspired by
\emph{focusing} in automated proof search.
% TODO sources for focusing

\section{Matching}

In this section we will try to formalize how the matching (unification) is done
in FCG. To do that, we must first define what a lisp term is.

\subsection{Lisp Terms}

\begin{defi}{Lisp term}
    \[\begin{array}{rcll}
        t & = & ?v       & \text{variable} \\
          & | & s        & \text{symbol}   \\
          & | & t . t    & \text{cons}     \\
          & | & ()_{ann} & \text{nil}      \\
    \end{array}\]

    Where $a$ is a type annotation that tells us how the list should be
    interpreted.
\end{defi}

Let's write $LT$ the set of lisp terms defined according to the above
definition. To make it more readable, we write
$a.b.\cdots.()_{ann} = (a\ b\ \cdots)_{ann}$.

We write the set of all lisp terms $\mathbb{L}$. Since they play a specific
role, we also need a specific set for variables $\mathbb{V}$. We assume we have
a total order $\leq_\mathbb{V}$ on $\mathbb{V}$.

\begin{ex}{Some lisp terms}\begin{itemize}
    \item The list with the symbols $x$, $y$ and the variable $v$~:
        $x.y.?v.() = (x\ y\ ?v)_{list}$
    \item Another list, with longer symbols~: $(print ?x)$
    \item A set with some symbols and variables~: $(x\ y\ x\ ?v\ x)_{set}$. Notice
        how the set can have more than one occurrence of a symbol or variable, indeed
        it is just a list with an annotation saying it should be treated as a set.
    \item A more complicated term~: $(return\ ((print\ (a\ b\ ?v)_{set}\ ?u)_{fun})_{fun}$
\end{itemize}\end{ex}

\subsection{Substitution}

What an unification algorithm does is to find a \emph{substitution} (or matching in
FCG terms) to make two terms equals. To be able to express it, we must thus define
what a substitution is, and them how is equality computed.

\begin{defi}{Substitution}
    A substitution is a partial function $\theta$ from variables to lisp terms.

    We note $\text{dom}(\theta)$ the variables for which it is defined.

    We write the set of all substitution $\mathbb{S}$.
\end{defi}

A substitution itself is only useful if we know how to apply it to any lisp
term. We must then define the application of a substitution.

\begin{defi}{Application of substitution}
    We define the application $l\theta$ of the substitution $\theta$ to the
    lisp term $l$ inductively on the definition of $l$~:
    \[\begin{array}{rcl}
        l\theta & = & \left|\begin{array}{ll}
                          \theta(?v) & \text{if } ?v\in\dom(\theta) \\
                          ?v         & \text{otherwise}
                      \end{array}\right. \\
                & | & s \\
                & | & t\theta.t\theta \\
                & | & ()_{ann} \\
    \end{array}\]
\end{defi}

But what FCG matching computes is not any substitution but a binding, ie a list
of pairs, with the first element a variable and the second one a lisp term in which
the variable does not occur (we assume the matching would have failed in case of
a circular binding). We write the set of all bindings $\mathbb{B}$.

We must now give a way to transform a binding into a substitution (the other way is
easy if the substitution has a finite domain, just link $?v$ to $f(?v)$ for
$?v\in\text{dom}(f)$). Let's note this binding $\B(f)$.

\begin{defi}{$\theta$}
    If $b$ is a binding, we define $\theta(b)$ a substitution associated. We define
    it inductively on the length of $b$.

    If $b$ is the empty list, $\theta(b)$ is the substitution with empty domain.

    If $b$ is the list with head $(u,v)$ where $u,v\in\mathbb{V}$, $v <_\mathbb{V} u$,
    and tail $tl$, we set $\theta(b) = \theta((v,u) :: tl)$.

    If $b$ is the list with head $(v,t)$ and tail $tl$, we construct $\theta(b)$ by
    updating $\theta(tl)$. Let $f = \theta(tl)$. If $v\not\in\dom(f)$ and $t\not\in\dom(f)$,
    we define~:
    \[\theta(b) : x \mapsto \left\{\begin{array}{ll}
        t & \text{if } x = v \\
        t & \text{if } x = t \\
        f(x) & \text{if } x\in\dom(f) \\
    \end{array}\right.\]

    Else if $v\not\in\dom(f)$ and $t\in\dom{f}$, we define~:
    \[\theta(b) : x\mapsto\left\{\begin{array}{ll}
        f(t) & \text{if } x = v \\
        f(x) & \text{if } x\in\dom(f) \\
    \end{array}\right.\]

    Else if $v\in\dom(f)$, and $t\not\in\dom(f)$, we define~:
    \[\theta(b) : x \mapsto \left\{\begin{array}{ll}
        t & \text{if } x\in f^{-1}(f(v)) \\
        t & \text{if } x = t \\
        f(x) & \text{if } x\in\dom(f) - f^{-1}(f(v)) - \{t\} \\
    \end{array}\right.\]

    Else if $v\in\dom(f)$, and $t\in\dom(f)$, we define~:
    \[\theta(b) : x \mapsto \left\{\begin{array}{ll}
        f(t) & \text{if } x\in f^{-1}(f(v)) \\
        f(x) & \text{if } x\in\dom(f) - f^{-1}(f(v)) \\
    \end{array}\right.\]
\end{defi}

\subsection{Proof of $\theta(b)$}

Now we would like to prove that this definition is correct, in other words that
$\forall b\in\mathbb{B}. \B(\theta(b)) = b$. But strict syntactical equality is not
sufficient for comparing bindings. Indeed, bindings are the same up to permutation, but
even that is too weak. For example, $[(?v, ?u), (?u, t)]$ and $[(?u, ?v), (?v, t)]$
are semantically the same. We need a stronger definition.

\begin{defi}{Graph associated to a binding}
    Let $b$ be a binding. We note $\G(b)$ the undirected graph which vertices
    are all the lisp terms that appears in $b$, and has edges between the terms
    that are bound by the binding.
\end{defi}

\begin{ex}{$G([(?v,?u), (?u,t), (?w,t')])$}
    \newline
    \begin{center}
        \input{binding-ex}
    \end{center}
\end{ex}

Let's write $\text{CC}(\G)$ to denote the set of connected components of the
graph $\G$ (as a set of set of nodes).

\begin{defi}{Equivalence of bindings}
    Two bindings $b_1$ and $b_2$ are equivalent, written $b_1\sim b_2$,
    if $\text{CC}(\G(b_1)) = \text{CC}(\G(b_2))$.
\end{defi}

Now that we have the definition of $\theta$ and our effective equality
for bindings, we can proceed to the main theorem.

\begin{theo}{Congruence of $\theta$}\label{theta-congru}
    \[\forall b_1,b_2\in\mathbb{B}.
    \theta(b_1) = \theta(b_2)\iff b_1\sim b_2\]
\end{theo}

We can't prove it directly, we must first establish a few lemmas.

\begin{lem}\label{image_connected}
    \[\forall b\in\mathbb{B}. \forall x\in\dom(\theta(b)). \forall t\in\mathbb{L}.
    \theta(b)(x) = t
    \implies\exists c\in\text{CC}(\G(b)). x\in c\wedge t\in c\]
\end{lem}

\begin{prf}
    Let's proceed by induction on $b\in\mathbb{B}$~:\begin{itemize}
        \item If $b$ is the empty binding, $\dom(\theta(b)) = \emptyset$ thus the
            lemma is true.
        \item If $b$ is the list with head $(v,t)$ and tail $tl$. Let $f = \theta(tl)$.
            By induction the proposition holds for $f$. Let $x\in\dom(\theta(b))$ and 
            $t' = \theta(b)(x)$.
            We must distinguish four subcases~:\begin{itemize}
                \item If $v\not\in\dom(f)$ and $t\not\in\dom(f)$. If $x = v$ or if
                    $x = t$ then $t' = t$, thus the proposition holds. Otherwise
                    $t' = f(x)$ thus by induction they are connected in $\G(tl)$.
                    Since $\G(tl)$ is a subgraph of $\G(b)$, they are also connected
                    in it.
                \item $v\not\in\dom(f)$ and $t\in\dom(f)$. If $x = v$ then $t' = t$ and
                    the result holds. Otherwise $t' = f(x)$, and the same argument as
                    above applies.
                \item $v\in\dom(f)$ and $t\not\in\dom(f)$. If $x = t$ the result
                    is trivial. If $x\in f^{-1}(f(v))$, we have $t' = t$. And we have
                    $f(x) = f(v)$, thus $x$ is connected to $f(v)$ by induction. Also
                    by induction $v$ is connected to $f(v)$. Thus $x$ is connected to
                    $v$ in $\G(tl)$ thus in $\G(b)$. Since $v$ is connected to $t=t'$,
                    we can conclude. Otherwise $t' = f(x)$ and the same argument as above
                    applies.
                \item $v\in\dom(f)$ and $t\in\dom(f)$. If $x\in f^{-1}(f(v))$, the same
                    argument as above gives us $x$ connected to $t$. Since by induction
                    $t$ is connected to $f(t) = t'$, we can conclude. Otherwise it is the
                    same as always.
            \end{itemize}
    \end{itemize}
\end{prf}

We can thus give the following lemma~:

\begin{lem}\label{subst_connection}
    \[\forall b\in\mathbb{B}. \forall x, y\in\dom(\theta(b)).
    \theta(b)(x) = \theta(b)(y) \iff
    \exists c\in\text{CC}(\G(b)). x\in c\wedge y\in c\]
\end{lem}

In other words, two variables have the same image by $\theta(b)$ if and only if
they are connected by the binding.

\begin{prf}
    \paragraph{$\implies$} Immediate application of lemma \ref{image_connected}.

    \paragraph{$\impliedby$} If $x=y$, the result is immediate by induction.
    
    By immediate induction, we can show that if two variables
    have the same image by $\theta(b)$, they have the same image by any $\theta(b')$
    where $b'$ is $b$ with additional bindings. This will allow us to restrict ourselves
    to postfixes of $b$. Furthermore, a path between two variables can have at most
    one lisp term which is not a variable (otherwise the binding would be incorrect).
    Thus we only need to treat the cases were $x$ and $y$ are either adjacent or
    separated by a non-variable.
    
    In this second case, ie $(x,t)\in b$ and $(y,t)\in b)$, it is immediate that
    $\theta(b)(x) = t = \theta(b)(y)$.

    We must now treat the case when $(x,y)\in b$ or $(y,x)\in b$. These cases are
    symmetric and we can furthermore assume $(x,y)$ s the head of $b$. Let
    $f = \theta(b')$ where $b'$ is the tail of $b$. The result is obtained by a
    disjunction on whether $x\in\dom(f)$ and $y\in\dom(f)$.
\end{prf}

\begin{lem}\label{ordered_theta}
    \[\forall b\in\mathbb{B}. \forall x\in\dom(\theta(b)).
    \theta(b)(x)\not\in\mathbb{V}\vee \theta(b)(x)\leq_\mathbb{V} x\]
\end{lem}

This lemma is immediate.

The proof of the theorem \ref{theta-congru} is now pretty straightforward.

\begin{prf}
    Lemma \ref{subst_connection} and lemma \ref{ordered_theta} tell us that $\theta(b)$
    is a function that links a variable $v$ to the unique not-variable term in its
    connected component if any, or to the smallest (by $\leq_\mathbb{V}$) variable in its
    component otherwise. In other words, it deterministically choose an element of the
    connected component of its argument.

    Thus it holds all information about the connected components, and can be determined
    only by them.
\end{prf}

\begin{theo}{Correction of $\theta$}
    \[ \forall b\in\mathbb{B}. \B(\theta(b)) \sim b \]
\end{theo}
\begin{prf}
    The interpretation of $\theta$ as the function choosing a representant for the
    connected component of its argument gives us this result~: $\G(\B(\theta(b)))$ is
    basically $\G(\theta(b))$ were all nodes have been moved to distance 1 of the
    representant of their connected component.
\end{prf}

\subsection{Lisp equality}

We will now assume that the annotation of lists in terms is one of $\{\text{list},
\text{map}, \text{set}\}$ and that we have annotation for symbols and variables
of the same kind. In case the annotation is $\text{map}$, we assume the list is of
even length, of the form $(key_1\ value_1\ key_2\ value_2\dots)_\text{map}$.

We now want to define an equality for lisp terms.

\subsubsection{Syntactical equality}

For variables, symbols and lists, syntactical equality is sufficient. That means
that $?v = ?u \iff u = v$, same for symbols. For lists, it means that~:
\[\left|\begin{array}{l}
    t_1._\text{list}t_2 = t_1'._\text{list}t_2'\iff t_1 = t_1' \wedge t_2 = t_2'\\
    ()_\text{list} = ()_\text{list} \\
\end{array}\right.\]

\subsubsection{Set equality}

Set equality is a bit more complicated in that it can't be defined directly by
induction on the syntactical definition. First we must define a relation denotating the
appartenance of an element in a set~:
\[t\in t_1._\text{set}t_2\iff t = t_1\vee t\in t_2\]

With that we can define the inclusion of a set into another by~:
\[\left|\begin{array}{l}
    t_1._\text{set}t_2\subset s\iff t_1\in s\wedge t_2\subset s \\
    ()_\text{set}\subseteq s \\
\end{array}\right.\]

Set equality is thus simply mutual inclusion
$s_1= s_2\iff s_1\subset s_2\wedge s_2\subset s_1$.

Notice how this definition gives us $(a a a)_\text{set} = (a)_\text{set}$.

\subsubsection{Map equality}

For maps, the basic operations is the \emph{lookup}. Basically two maps are
equals if they have the same keys and lookup on the same key give the same
value.

So first we define the lookup~:
\[\text{lookup}\ k\ t._\text{map} t'._\text{map}.tl = v \iff
(k = t\wedge v = t')\vee \text{lookup}\ k\ tl = v \]

Then we can define the set of keys of a map~:
\[\left|\begin{array}{l}
    \text{keys}\ k._\text{map}v._\text{map}.t = k._\text{set}\text{keys}\ t \\
    \text{keys}\ ()_\text{map} = ()_\text{set} \\
\end{array}\right.\]

Now we can define the equality on a set for two maps (this is only well defined
if the considered set is included in the intersection of keys of the two maps)~:
\[\left|\begin{array}{l}
    m_1 =_{k.ks} m_2 \iff \text{lookup}\ k\ m_1 = \text{lookup}\ k\ m_2
                          \wedge m_1 =_{ks} m_2 \\
    m_1 =_{()_\text{set}} m_2 \\
\end{array}\right.\]

Finally, we can define the equality of two maps as having the same keys and
being equal on this set~:

\[m_1 = m_2 \iff \text{keys}\ m_1 = \text{keys}\ m_2
                 \wedge m_1 =_{\text{keys}\ m_1} m_2 \]

\subsection{Unification reformulation}

We can now give a formal definition to unification~: two terms $t_1$ and $t_2$ are
unifiable if a finite binding $b$ exits such that $t_1\theta(b) = t_2\theta(b)$.

This definition has the advantage of formalism, but is a bit painful to manipulate.
We want to reformulate it as the existence of a proof of equality in a well
chosen logic. The next section will introduce such a logic, and we will then focus
on translating lisp terms to this logic.

\section{The logic system}

We first add the usual axioms of equational logic (LE),
in a many-sorted like manner (every equality is between element
of the same sort, and the equality itself is of sort $\Prop$)~:

\[\text{LE}\left\{
\begin{gathered}
\proof{
    \hypo{M : \sigma}
    \infer1[R]{M =_\sigma M : \Prop}
}
\qquad\proof{
    \hypo{ N =_\sigma M : \Prop }
    \infer1[S]{M =_\sigma N : \Prop}
}
\qquad\proof{
    \hypo{M=_\sigma N : \Prop}
    \hypo{N=_\sigma O : \Prop}
    \infer2[T]{M=_\sigma O : \Prop}
} \\
\proof{
    \hypo{M=_\sigma N:\Prop}
    \hypo{C[N]=_\tau O:\Prop}
    \infer2[IL]{C[M]=_\tau O : \Prop}
}
\qquad\proof{
    \hypo{M =_\sigma C[N]:\Prop}
    \hypo{N =_\tau O:\Prop}
    \infer2[IR]{M =_\sigma C[O]:\Prop}
} \\
\proof{
    \hypo{C[N]=_\sigma D[M]:\Prop}
    \hypo{C[\_]\sim D[\_]}
    \hypo{N:\sigma}
    \hypo{M:\sigma}
    \infer4[E]{N=_\sigma M:\Prop}
}
\end{gathered}
\right.
\]

Then we need two sorts for lisp symbols and variables. We assume they
are given as two sets $\S$ for symbols and $\V$ for variables.
Furthermore, while this logic focus on equality, and it is not possible
to express inequality for generic sort, we make equality for $\S$
decidable.

\[\text{LE}_\text{lisp}\left\{
    \begin{gathered}
        \proof{
            \infer0[IS (for $s\in\S$)]{s : \Sym}
        }
        \qquad\proof{
            \infer0[IV (for $v\in\V)$]{v : \Var}
        }\\
        \proof{
            \infer0[SNE (for $s_1\neq s_2\in\S$)]{s_1\neq s_2:\Prop}
        }
    \end{gathered}
\right.\]

Now that we have the basic sorts, we must add axioms for more complicated
structures. Let's start with sequences~:

\[\text{LE}_\text{Seq}\left\{
    \begin{gathered}
        \proof{
            \infer0[SNil]{[]:\Seq}
        }
        \qquad\proof{
            \hypo{x:\sigma}
            \hypo{l:\Seq}
            \infer2[SCons]{x::l : \Seq}
        }
    \end{gathered}
\right.\]

More complicated, maps of symbols to any sort~:

\[\text{LE}_\text{Map}\left\{
    \begin{gathered}
        \proof{
            \infer0[EmptyMap]{\theta:\Map}
        }
        \qquad\proof{
            \hypo{k : \Sym}
            \hypo{v : \sigma}
            \hypo{m : \Map}
            \infer3[InsertMap]{m[k\rightarrow v] : \Map}
        }\\
        \proof{
            \hypo{k : \Sym}
            \hypo{v : \sigma}
            \hypo{m : \Map}
            \infer3[LookupEnd]{m[k\rightarrow v]k =_\sigma v:\Prop}
        }\\
        \proof{
            \hypo{m : \Map}
            \hypo{k_1\neq k_2 : \Prop}
            \hypo{m k_1 =_\sigma v_1 : \Prop}
            \hypo{v_2 : \tau}
            \infer4[LookupRec]{m[k_2\rightarrow v_2]k_2 =_\sigma v_1 : \Prop}
        }\\
        \proof{
            \hypo{m : \Map}
            \hypo{v_1 : \sigma}
            \hypo{v_2 : \tau}
            \hypo{k_1\neq k_2 : \Prop}
            \infer4[InsCom]{m[k_1\rightarrow v_1][k_2\rightarrow v_2] =_\Map
                    m[k_2\rightarrow v_2][k_1\rightarrow v_1] : \Prop}
        }\\
        \proof{
            \hypo{m : \Map}
            \hypo{v_1 : \sigma}
            \hypo{v_2 : \tau}
            \hypo{k : \Sym}
            \infer4[InsIdem]{m[k\rightarrow v_1][k\rightarrow v_2] =_\Map
                    m[k\rightarrow v_2] : \Prop}
        }
    \end{gathered}
\right.\]

Finally, we must have a way to manipulate sets of a certain sort. Since it is pretty
complicated, we will split it in two sets of definitions. The first one deals with
the algebra of sets relative to union and intersection. The second one defines the
inclusion property of sets.

\[\text{LE}_\text{Set}\left\{
    \begin{gathered}
        \proof{
            \hypo{x:\sigma}
            \infer1[Sing]{\{x\} : \Set}
        }
        \qquad\proof{
            \infer0[EmptySet]{\emptyset : \Set}
        }
        \qquad\proof{
            \infer0[Universe]{U : \Set}
        }\\
        \proof{
            \hypo{A, B : \Set}
            \infer1[Union]{A\cup B : \Set}
        }
        \qquad\proof{
            \hypo{A, B : \Set}
            \infer1[Intersec]{A\cap B: \Set}
        }\\
        \proof{
            \hypo{A : \Set}
            \infer1[UIdem]{A\cup A =_{\Set} A : \Prop}
        }
        \qquad\proof{
            \hypo{A, B : \Set}
            \infer1[UComm]{A\cup B =_{\Set} B\cup A : \Prop}
        }\\
        \proof{
            \hypo{A, B, C : \Set}
            \infer1[UAssoc]{A\cup (B\cup C) =_{\Set} (A\cup B)\cup C : \Prop}
        }\\
        \proof{
            \hypo{A : \Set}
            \infer1[IntIdem]{A\cap A =_{\Set} A : \Prop}
        }
        \qquad\proof{
            \hypo{A, B : \Set}
            \infer1[IntComm]{A\cap B =_{\Set} B\cap A : \Prop}
        }\\
        \proof{
            \hypo{A, B, C : \Set}
            \infer1[IntAssoc]{A\cap (B\cap C) =_{\Set} (A\cap B)\cap C : \Prop}
        }\\
        \proof{
            \hypo{A, B, C : \Set}
            \infer1[UDistrib]{A\cup (B\cap C) =_{\Set}
                              (A\cap B) \cup (B\cap C) : \Prop}
        }\\
        \proof{
            \hypo{A, B, C : \Set}
            \infer1[IDistrib]{A\cap (B\cup C) =_{\Set}
                              (A\cup B) \cap (B\cup C) : \Prop}
        }\\
        \proof{
            \hypo{A : \Set}
            \infer1[UEmpty]{A\cup \emptyset =_{\Set} A : \Prop}
        }
        \qquad\proof{
            \hypo{A : \Set}
            \infer1[UUniv]{A\cup U =_{\Set} U : \Prop}
        }\\
        \proof{
            \hypo{A : \Set}
            \infer1[UEmpty]{A\cap \emptyset =_{\Set}
                            \emptyset : \Prop}
        }
        \qquad\proof{
            \hypo{A : \Set}
            \infer1[UUniv]{A\cup U =_{\Set} A : \Prop}
        }\\
    \end{gathered}
\right.\]

And now the axioms for inclusion~:

\[\text{LE}_\subset\left\{
    \begin{gathered}
        \proof{
            \hypo{A:\Set}
            \infer1[IncRefl]{A\subset A : \Prop}
        }
        \qquad\proof{
            \hypo{A\subset B : \Prop}
            \hypo{B\subset C : \Prop}
            \infer2[IncTrans]{A\subset C:\Prop}
        }\\
        \proof{
            \hypo{A\subset B : \Prop}
            \hypo{B\subset A : \Prop}
            \infer2[IncAnti]{A =_\Set B : \Prop}
        }\\
        \proof{
            \hypo{A : \Set}
            \infer1[IncUni]{A\subset_\Set U : \Prop}
        }
        \qquad\proof{
            \hypo{A : \Set}
            \infer1[IncEmpty]{\emptyset\subset A : \Prop}
        }\\
        \proof{
            \hypo{A, B : \Set}
            \infer1[IncUni]{A \subset A\cup B : \Prop}
        }
        \qquad\proof{
            \hypo{A, B : \Set}
            \infer1[IncInter]{A\cap B\subset A : \Prop}
        }\\
        \proof{
            \hypo{A=_\Set C : \Prop}
            \hypo{B=_\Set D : \Prop}
            \hypo{A \subset B : \Prop}
            \infer3[IncEq]{C\subset D : \Prop}
        }
    \end{gathered}
\right.\]

\begin{defi}{Derivation}
    If an expression $E$ can be derived from a set of hypothesis $\Gamma$
    according to the previous logic, we write $\Gamma\vdash E$.

    If $\Gamma = \emptyset$, we can write $\vdash E$.
\end{defi}

\section{A deductive formulation of unification}

Now that we have formalized lisp terms and a logic system, we need we way to
\emph{translate} the lisp terms in this system. We will write the translation
of a lisp term $\sem{t}$.

\subsection{Translating lisp term into the logic system}

\subsubsection{Translation}

The logic system will have $\S$ the set of all lisp symbols and $\V$ the set
of all lisp variables. If $s$ is a symbol, we define $\sem{s} = s$. If $v$ is a
variable, we define $\sem{v} = v$.

Since we created the logic for this, the translation are pretty straightforward.
Here is the translation of a list~:
\[\left|\begin{array}{lcl}
    \sem{t._\text{list} t'} & = & \sem{t} :: \sem{t'} \\
    \sem{()_\text{list}}    & = & [] \\
\end{array}\right.\]

Translation for maps~:
\[\left|\begin{array}{lcl}
    \sem{k._\text{map}v._\text{map}m} & = & \sem{m}[\sem{k}\rightarrow\sem{v}] \\
    \sem{()_\text{map}} & = & \theta \\
\end{array}\right.\]

And the translation for sets~:

\[\left|\begin{array}{lcl}
    \sem{x._\text{set} s} & = & \{\sem{x}\}\cup\sem{s} \\
    \sem{()_\text{set}} & = & \emptyset \\
\end{array}\right.\]

It is easy to show that these constructions are valid, ie~:

\[\begin{gathered}
    \vdash \sem{s}:\Sym\qquad\vdash \sem{v}:\Var \\
    \vdash \sem{t_\text{list}}:\Seq
    \qquad\vdash\sem{t_\text{map}}:\Map
    \qquad\vdash\sem{t_\text{set}}:\Set
\end{gathered}\]

\subsubsection{Correction}

It is trivial to show that $s_1 = s_2 \iff \vdash \sem{s_1} = \sem{s_2}$, and
the same for variables and lists (assuming the results holds for the contents of
the list).

% TODO


\end{document}
